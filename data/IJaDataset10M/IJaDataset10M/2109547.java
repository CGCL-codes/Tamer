package edu.cmu.sphinx.linguist.language.ngram;

import java.util.Scanner;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.PrintWriter;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedHashMap;
import java.util.Map;
import java.util.Set;
import java.util.logging.Logger;
import java.util.logging.Level;
import java.io.File;
import edu.cmu.sphinx.linguist.WordSequence;
import edu.cmu.sphinx.linguist.dictionary.Dictionary;
import edu.cmu.sphinx.linguist.dictionary.Word;
import edu.cmu.sphinx.linguist.language.ngram.LanguageModel;
import edu.cmu.sphinx.util.LogMath;
import edu.cmu.sphinx.util.Timer;
import edu.cmu.sphinx.util.props.PropertyException;
import edu.cmu.sphinx.util.props.PropertySheet;
import edu.cmu.sphinx.util.props.PropertyType;
import edu.cmu.sphinx.util.props.Registry;

/**
 * Queries a binary language model file generated by the 
 * <a href="http://www.speech.cs.cmu.edu/SLM_info.html">
 * CMU-Cambridge Statistical Language Modelling Toolkit</a>.
 * 
 * Note that all probabilites in the grammar are stored in LogMath log base
 * format. Language Probabilties in the language model file are stored in log
 * 10 base. They are converted to the LogMath logbase.
 */
public class ClasseGramModel implements LanguageModel {

    /**
     * Sphinx property for the name of the file that logs all the queried
     * N-grams. If this property is set to null, it means that the queried
     * N-grams are not logged.
     */
    public static final String PROP_QUERY_LOG_FILE = "queryLogFile";

    /**
     * The default value for PROP_QUERY_LOG_FILE.
     */
    public static final String PROP_QUERY_LOG_FILE_DEFAULT = null;

    /**
     * A sphinx property that defines that maxium number of trigrams to be
     * cached
     */
    public static final String PROP_CACHE_SIZE = "cacheSize";

    /**
     * The default value for the PROP_TRIGRAM_CACHE_SIZE property
     */
    public static final int PROP_CACHE_SIZE_DEFAULT = 100000;

    /**
     * A sphinx property that controls whether the bigram and trigram caches
     * are cleared after every utterance
     */
    public static final String PROP_CLEAR_CACHES_AFTER_UTTERANCE = "clearCachesAfterUtterance";

    /**
     * The default value for the PROP_CLEAR_CACHES_AFTER_UTTERANCE property
     */
    public static final boolean PROP_CLEAR_CACHES_AFTER_UTTERANCE_DEFAULT = false;

    /**
     * Sphinx property that defines the language weight for the search
     */
    public static final String PROP_LANGUAGE_WEIGHT = "languageWeight";

    /**
     * The default value for the PROP_LANGUAGE_WEIGHT property
     */
    public static final float PROP_LANGUAGE_WEIGHT_DEFAULT = 1.0f;

    /**
     * Sphinx property that defines the logMath component.
     */
    public static final String PROP_LOG_MATH = "logMath";

    /**
     * Sphinx propert that controls whether or not the language model will
     * apply the language weight and word insertion probability
     */
    public static final String PROP_APPLY_LANGUAGE_WEIGHT_AND_WIP = "applyLanguageWeightAndWip";

    /**
     * The default value for PROP_APPLY_LANGUAGE_WEIGHT_AND_WIP
     */
    public static final boolean PROP_APPLY_LANGUAGE_WEIGHT_AND_WIP_DEFAULT = false;

    /**
     * Word insertion probability property
     */
    public static final String PROP_WORD_INSERTION_PROBABILITY = "wordInsertionProbability";

    /**
     * The default value for PROP_WORD_INSERTION_PROBABILITY
     */
    public static final double PROP_WORD_INSERTION_PROBABILITY_DEFAULT = 1.0;

    /**
      * If true, use full bigram information to determine smear
      */
    public static final String PROP_FULL_SMEAR = "fullSmear";

    /**
      * Default value for PROP_FULL_SMEAR
      */
    public static final boolean PROP_FULL_SMEAR_DEFAULT = false;

    /**
     * The number of bytes per bigram in the LM file generated by the
     * CMU-Cambridge Statistical Language Modelling Toolkit.
     */
    public static final String PROP_DICTIONARY_CLASSE = "dictionaryClasse";

    private Logger logger;

    private LogMath logMath;

    private String name;

    private String ngramLogFile;

    private int maxCacheSize;

    private boolean clearCacheAfterUtterance;

    private boolean fullSmear;

    private int maxDepth;

    private Dictionary dictionary;

    private Dictionary dictionaryClasse;

    private LanguageModel wordLM;

    private LanguageModel basicLM;

    private LanguageModel classeLM;

    private String format;

    private File location;

    private boolean applyLanguageWeightAndWip;

    private float languageWeight;

    private double wip;

    private float unigramWeight;

    private float poids;

    private int misses;

    private int hit;

    private int smearTermCount = 0;

    private PrintWriter logFile;

    private Map unigramIDMap;

    private LRUCache cache;

    private Map bigramSmearMap;

    public void register(String name, Registry registry) throws PropertyException {
        this.name = name;
        registry.register(PROP_FORMAT, PropertyType.STRING);
        registry.register(PROP_LOCATION, PropertyType.STRING);
        registry.register(PROP_QUERY_LOG_FILE, PropertyType.STRING);
        registry.register(PROP_CACHE_SIZE, PropertyType.INT);
        registry.register(PROP_CLEAR_CACHES_AFTER_UTTERANCE, PropertyType.BOOLEAN);
        registry.register(PROP_MAX_DEPTH, PropertyType.INT);
        registry.register(PROP_LOG_MATH, PropertyType.COMPONENT);
        registry.register(PROP_DICTIONARY, PropertyType.COMPONENT);
        registry.register(PROP_DICTIONARY_CLASSE, PropertyType.COMPONENT);
        registry.register("wordLM", PropertyType.COMPONENT);
        registry.register("classeLM", PropertyType.COMPONENT);
        registry.register("basicLM", PropertyType.COMPONENT);
        registry.register("poids", PropertyType.FLOAT);
        registry.register(PROP_APPLY_LANGUAGE_WEIGHT_AND_WIP, PropertyType.BOOLEAN);
        registry.register(PROP_LANGUAGE_WEIGHT, PropertyType.FLOAT);
        registry.register(PROP_WORD_INSERTION_PROBABILITY, PropertyType.DOUBLE);
        registry.register(PROP_UNIGRAM_WEIGHT, PropertyType.FLOAT);
        registry.register(PROP_FULL_SMEAR, PropertyType.BOOLEAN);
    }

    public void newProperties(PropertySheet ps) throws PropertyException {
        logger = ps.getLogger();
        format = ps.getString(LanguageModel.PROP_FORMAT, LanguageModel.PROP_FORMAT_DEFAULT);
        location = new File(ps.getString(PROP_LOCATION, PROP_LOCATION_DEFAULT));
        ngramLogFile = ps.getString(PROP_QUERY_LOG_FILE, PROP_QUERY_LOG_FILE_DEFAULT);
        maxCacheSize = ps.getInt(PROP_CACHE_SIZE, PROP_CACHE_SIZE_DEFAULT);
        clearCacheAfterUtterance = ps.getBoolean(PROP_CLEAR_CACHES_AFTER_UTTERANCE, PROP_CLEAR_CACHES_AFTER_UTTERANCE_DEFAULT);
        maxDepth = ps.getInt(LanguageModel.PROP_MAX_DEPTH, LanguageModel.PROP_MAX_DEPTH_DEFAULT);
        logMath = (LogMath) ps.getComponent(PROP_LOG_MATH, LogMath.class);
        dictionary = (Dictionary) ps.getComponent(PROP_DICTIONARY, Dictionary.class);
        wordLM = (LanguageModel) ps.getComponent("wordLM", LanguageModel.class);
        applyLanguageWeightAndWip = ps.getBoolean(PROP_APPLY_LANGUAGE_WEIGHT_AND_WIP, PROP_APPLY_LANGUAGE_WEIGHT_AND_WIP_DEFAULT);
        languageWeight = ps.getFloat(PROP_LANGUAGE_WEIGHT, PROP_LANGUAGE_WEIGHT_DEFAULT);
        poids = ps.getFloat("poids", 0.8f);
        classeLM = null;
        if (poids < 1.0) {
            classeLM = (LanguageModel) ps.getComponent("classeLM", LanguageModel.class);
            dictionaryClasse = (Dictionary) ps.getComponent(PROP_DICTIONARY_CLASSE, Dictionary.class);
        }
        try {
            basicLM = (LanguageModel) ps.getComponent("basicLM", LanguageModel.class);
        } catch (Exception e) {
            basicLM = null;
            logger.warning(e.toString());
        }
        wip = ps.getDouble(PROP_WORD_INSERTION_PROBABILITY, PROP_WORD_INSERTION_PROBABILITY_DEFAULT);
        fullSmear = ps.getBoolean(PROP_FULL_SMEAR, PROP_FULL_SMEAR_DEFAULT);
    }

    public String getName() {
        return name;
    }

    private int maxDepthWord = 0;

    public void allocate() throws IOException {
        Timer.start("LM Load");
        wordLM.allocate();
        maxDepthWord = wordLM.getMaxDepth();
        if (basicLM != null) {
            basicLM.allocate();
        } else maxDepthWord = 0;
        if (classeLM == null) {
            if (maxDepth > wordLM.getMaxDepth()) maxDepth = wordLM.getMaxDepth();
            return;
        }
        dictionaryClasse.allocate();
        classeLM.allocate();
        java.io.BufferedReader fichier = new java.io.BufferedReader(new java.io.FileReader(location));
        buildClasse(fichier, dictionary, dictionaryClasse);
        if (ngramLogFile != null) {
            logFile = new PrintWriter(new FileOutputStream(ngramLogFile));
        }
        cache = new LRUCache(maxCacheSize);
        if (wordLM.getMaxDepth() < maxDepth) maxDepth = wordLM.getMaxDepth();
        if (classeLM.getMaxDepth() < maxDepth) maxDepth = classeLM.getMaxDepth();
        if (fullSmear) {
            throw new Error("pas fullsmear fait ");
        }
        Timer.stop("LM Load");
    }

    public int getMaxDepth() {
        return maxDepth;
    }

    public void deallocate() {
    }

    /**
     * Builds the map from unigram to unigramID. Also finds the startWordID and
     * endWordID.
     */
    private void buildClasse(java.io.BufferedReader fichier, Dictionary dico, Dictionary classes) throws IOException {
        String ligne;
        float proba;
        Word w1, w2;
        String nombre;
        dico.getSentenceStartWord().setClasse(classes.getSentenceStartWord(), 0.0f);
        dico.getSentenceEndWord().setClasse(classes.getSentenceEndWord(), 0.0f);
        while ((ligne = fichier.readLine()) != null) {
            Scanner s = new Scanner(ligne);
            w1 = dico.getWord(s.next());
            w2 = classes.getWord(s.next());
            proba = Float.parseFloat(s.next());
            proba = logMath.lnToLog(proba);
            if (w1 == null || w2 == null) {
                logger.warning(ligne + "non traite");
                continue;
            }
            if (logger.isLoggable(Level.FINE)) logger.fine(String.format("Word: %s classe: %s  p: %f", w1.toString(), w2.toString(), proba));
            w1.setClasse(w2, proba);
        }
    }

    /**
     * Called before a recognition
     */
    public void start() {
        wordLM.start();
        if (basicLM != null) basicLM.start();
        if (classeLM != null) classeLM.start();
        if (logFile != null) {
            logFile.println("<START_UTT>");
        }
    }

    /**
     * Called after a recognition
     */
    public void stop() {
        clearCache();
        wordLM.stop();
        if (classeLM != null) classeLM.stop();
        if (basicLM != null) basicLM.stop();
        if (logFile != null) {
            logFile.println("<END_UTT>");
            logFile.flush();
        }
    }

    /**
     * Clears the various N-gram caches.
     */
    private void clearCache() {
        if (clearCacheAfterUtterance) cache = new LRUCache(maxCacheSize);
    }

    /**
     * Gets the ngram probability of the word sequence represented by the word
     * list
     * 
     * @param wordSequence
     *                the word sequence
     * 
     * @return the probability of the word sequence. Probability is in logMath
     *         log base
     *  
     */
    public float getProbability(WordSequence wordSequence) {
        if (classeLM == null) return ((wordSequence.size() < maxDepthWord) ? basicLM.getProbability(wordSequence) : wordLM.getProbability(wordSequence));
        int numberWords = wordSequence.size();
        float ret = -Float.MAX_VALUE;
        float temp;
        float wordProba;
        if (logFile != null) {
            if (numberWords <= maxDepth) {
                Float proba = (Float) cache.get(wordSequence);
                if (proba != null) ret = proba; else {
                    ret = poids * ((wordSequence.size() < maxDepthWord) ? basicLM.getProbability(wordSequence) : wordLM.getProbability(wordSequence));
                    ret += (1.0f - poids) * (classeLM.getProbability(wordSequence.getClasse()) + (temp = wordSequence.getNewWord().getClasseProba()));
                    cache.put(wordSequence, ret);
                    logFile.format("%s %.0f %.0f\n", wordSequence.toText(), ret, temp);
                }
                if (ret != -Float.MAX_VALUE) return ret;
            }
            throw new Error("Unsupported N-gram: " + wordSequence.size());
        } else {
            if (numberWords <= maxDepth) {
                Float proba = (Float) cache.get(wordSequence);
                if (proba != null) ret = proba; else {
                    ret = poids * ((wordSequence.size() < maxDepthWord) ? basicLM.getProbability(wordSequence) : wordLM.getProbability(wordSequence)) + (1.0f - poids) * (classeLM.getProbability(wordSequence.getClasse()) + wordSequence.getNewWord().getClasseProba());
                    cache.put(wordSequence, ret);
                }
                if (ret != -Float.MAX_VALUE) return ret;
            }
            throw new Error("Unsupported N-gram: " + wordSequence.size());
        }
    }

    /**
     * Gets the smear term for the given wordSequence
     * 
     * @param wordSequence
     *                the word sequence
     * @return the smear term associated with this word sequence
     */
    public float getSmearOld(WordSequence wordSequence) {
        float smearTerm = 0.0f;
        return smearTerm;
    }

    int smearCount;

    int smearBigramHit;

    public float getSmear(WordSequence wordSequence) {
        float smearTerm = 1.0f;
        return smearTerm;
    }

    /**
     * Returns the set of words in the lanaguage model. The set is
     * unmodifiable.
     * 
     * @return the unmodifiable set of words
     */
    public Set getVocabulary() {
        return wordLM.getVocabulary();
    }

    /**
     * Returns the number of times when a bigram is queried, but there is no
     * bigram in the LM (in which case it uses the backoff probabilities).
     * 
     * @return the number of bigram misses
     */
    public int getBigramMisses() {
        return 0;
    }

    /**
     * Returns the number of times when a trigram is queried, but there is no
     * trigram in the LM (in which case it uses the backoff probabilities).
     * 
     * @return the number of trigram misses
     */
    public int getTrigramMisses() {
        return 0;
    }

    /**
     * Returns the number of trigram hits.
     * 
     * @return the number of trigram hits
     */
    public int getTrigramHits() {
        return 0;
    }
}

/**
 * An LRU cache
 */
class LRUCache extends LinkedHashMap {

    int maxSize;

    /**
     * Creates an LRU cache with the given maximum size
     * 
     * @param maxSize
     *                the maximum size of the cache
     */
    LRUCache(int maxSize) {
        this.maxSize = maxSize;
    }

    /**
     * Determines if the eldest entry in the map should be removed.
     * 
     * @param eldest
     *                the eldest entry
     * 
     * @return true if the eldest entry should be removed
     */
    protected boolean removeEldestEntry(Map.Entry eldest) {
        return size() > maxSize;
    }
}
