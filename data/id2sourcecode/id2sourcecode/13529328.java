    @SuppressWarnings("static-access")
    public static Options buildOptions() {
        Options options = new Options();
        options.addOption(OptionBuilder.withLongOpt("help").withDescription("Display these options.").hasArg(false).create());
        options.addOption(OptionBuilder.withLongOpt("sdfscli-password").withDescription("The password used to authenticate to the sdfscli management interface. Thee default password is \"admin\".").hasArg(true).withArgName("password").create());
        options.addOption(OptionBuilder.withLongOpt("sdfscli-require-auth").withDescription("Require authentication to connect to the sdfscli managment interface").hasArg(false).create());
        options.addOption(OptionBuilder.withLongOpt("sdfscli-listen-port").withDescription("TCP/IP Listenting port for the sdfscli management interface").hasArg(true).withArgName("tcp port").create());
        options.addOption(OptionBuilder.withLongOpt("sdfscli-listen-addr").withDescription("IP Listenting address for the sdfscli management interface. This defaults to \"localhost\"").hasArg(true).withArgName("ip address or host name").create());
        options.addOption(OptionBuilder.withLongOpt("base-path").withDescription("the folder path for all volume data and meta data.\n Defaults to: \n " + OSValidator.getProgramBasePath() + "<volume name>").hasArg().withArgName("PATH").create());
        options.addOption(OptionBuilder.withLongOpt("base-path").withDescription("the folder path for all volume data and meta data.\n Defaults to: \n " + OSValidator.getProgramBasePath() + "<volume name>").hasArg().withArgName("PATH").create());
        options.addOption(OptionBuilder.withLongOpt("gc-class").withDescription("The class used for intelligent block garbage collection.\n Defaults to: \n " + Main.gcClass).hasArg().withArgName("CLASS NAME").create());
        options.addOption(OptionBuilder.withLongOpt("dedup-db-store").withDescription("the folder path to location for the dedup file database.\n Defaults to: \n --base-path + " + File.separator + "ddb").hasArg().withArgName("PATH").create());
        options.addOption(OptionBuilder.withLongOpt("io-log").withDescription("the file path to location for the io log.\n Defaults to: \n --base-path + " + File.separator + "sdfs.log").hasArg().withArgName("PATH").create());
        options.addOption(OptionBuilder.withLongOpt("io-safe-close").withDescription("If true all files will be closed on filesystem close call. Otherwise, files will be closed" + " based on inactivity. Set this to false if you plan on sharing the file system over" + " an nfs share. True takes less RAM than False. \n Defaults to: \n true").hasArg().withArgName("true|false").create());
        options.addOption(OptionBuilder.withLongOpt("io-safe-sync").withDescription("If true all files will sync locally on filesystem sync call. Otherwise, by defaule (false), files will sync" + " on close and data will per written to disk based on --max-file-write-buffers.  " + "Setting this to true will ensure that no data loss will occur if the system is turned off abrubtly" + " at the cost of slower speed. \n Defaults to: \n false").hasArg().withArgName("true|false").create());
        options.addOption(OptionBuilder.withLongOpt("io-write-threads").withDescription("The number of threads that can be used to process data writted to the file system. \n Defaults to: \n 16").hasArg().withArgName("NUMBER").create());
        options.addOption(OptionBuilder.withLongOpt("io-dedup-files").withDescription("True mean that all files will be deduped inline by default. This can be changed on a one off" + "basis by using the command \"setfattr -n user.cmd.dedupAll -v 556:false <path to file on sdfs volume>\"\n Defaults to: \n true").hasArg().withArgName("true|false").create());
        options.addOption(OptionBuilder.withLongOpt("io-multi-read-timeout").withDescription("Timeout to try to read from cache before it request data from the chunkstore. \n Defaults to: \n 1000").hasArg().withArgName("NUMBER").create());
        options.addOption(OptionBuilder.withLongOpt("io-system-read-cache").withDescription("Size, in number of chunks, that read chunks will be cached into memory. \n Defaults to: \n 1000").hasArg().withArgName("NUMBER").create());
        options.addOption(OptionBuilder.withLongOpt("io-chunk-size").withDescription("The unit size, in kB, of chunks stored. Set this to 4 if you would like to dedup VMDK files inline.\n Defaults to: \n 128").hasArg().withArgName("SIZE in kB").create());
        options.addOption(OptionBuilder.withLongOpt("io-max-file-write-buffers").withDescription("The amount of memory to have available for reading and writing per file. Each buffer in the size" + " of io-chunk-size. \n Defaults to: \n 24").hasArg().withArgName("SIZE in MB").create());
        options.addOption(OptionBuilder.withLongOpt("io-file-read-cache").withDescription("The number of memory buffers to have available for reading per file. Each buffer in the size" + " of io-chunk-size. \n Defaults to: \n 5").hasArg().withArgName("NUMBER").create());
        options.addOption(OptionBuilder.withLongOpt("io-max-open-files").withDescription("The maximum number of files that can be open at any one time. " + "If the number of files is exceeded the least recently used will be closed. \n Defaults to: \n 1024").hasArg().withArgName("NUMBER").create());
        options.addOption(OptionBuilder.withLongOpt("io-meta-file-cache").withDescription("The maximum number metadata files to be cached at any one time. " + "If the number of files is exceeded the least recently used will be closed. \n Defaults to: \n 1024").hasArg().withArgName("NUMBER").create());
        options.addOption(OptionBuilder.withLongOpt("io-claim-chunks-schedule").withDescription("The schedule, in cron format, to claim deduped chunks with the Dedup Storage Engine. " + "This should happen more frequently than the chunk-store-gc-schedule. \n Defaults to: \n 0 0 0/1 * * ?").hasArg().withArgName("CRON Schedule").create());
        options.addOption(OptionBuilder.withLongOpt("permissions-file").withDescription("Default File Permissions. " + " \n Defaults to: \n 0644").hasArg().withArgName("POSIX PERMISSIONS").create());
        options.addOption(OptionBuilder.withLongOpt("permissions-folder").withDescription("Default Folder Permissions. " + " \n Defaults to: \n 0755").hasArg().withArgName("POSIX PERMISSIONS").create());
        options.addOption(OptionBuilder.withLongOpt("permissions-owner").withDescription("Default Owner. " + " \n Defaults to: \n 0").hasArg().withArgName("POSIX PERMISSIONS").create());
        options.addOption(OptionBuilder.withLongOpt("permissions-group").withDescription("Default Group. " + " \n Defaults to: \n 0").hasArg().withArgName("POSIX PERMISSIONS").create());
        options.addOption(OptionBuilder.withLongOpt("volume-capacity").withDescription("Capacity of the volume in [MB|GB|TB]. " + " \n THIS IS A REQUIRED OPTION").hasArg().withArgName("SIZE [MB|GB|TB]").create());
        options.addOption(OptionBuilder.withLongOpt("volume-name").withDescription("The name of the volume. " + " \n THIS IS A REQUIRED OPTION").hasArg().withArgName("STRING").create());
        options.addOption(OptionBuilder.withLongOpt("volume-maximum-full-percentage").withDescription("The maximum percentage of the volume capacity, as set by volume-capacity, before the volume starts" + "reporting that the disk is full. If the number is negative then it will be infinite. " + " \n e.g. --volume-maximum-full-percentage=100").hasArg().withArgName("PERCENTAGE").create());
        options.addOption(OptionBuilder.withLongOpt("chunk-store-local").withDescription("enables or disables local chunk store. The chunk store can be " + "local(true or remote(false) provided you supply the routing config file " + "and there is a storageHub listening on the remote server(s) when you " + "mount the SDFS volume." + " \nDefaults to: \n true").hasArg().withArgName("true|flase").create());
        options.addOption(OptionBuilder.withLongOpt("chunk-store-data-location").withDescription("The directory where chunks will be stored." + " \nDefaults to: \n --base-path + " + File.separator + "chunkstore" + File.separator + "chunks").hasArg().withArgName("PATH").create());
        options.addOption(OptionBuilder.withLongOpt("chunk-store-hashdb-location").withDescription("The directory where hash database for chunk locations will be stored." + " \nDefaults to: \n --base-path + " + File.separator + "chunkstore" + File.separator + "hdb").hasArg().withArgName("PATH").create());
        options.addOption(OptionBuilder.withLongOpt("chunk-store-pre-allocate").withDescription("Pre-allocate the chunk store if true." + " \nDefaults to: \n false").hasArg().withArgName("true|false").create());
        options.addOption(OptionBuilder.withLongOpt("chunkstore-class").withDescription("The class for the specific chunk store to be used. \n Defaults to org.opendedup.sdfs.filestore.FileChunkStore").hasArg().withArgName("Class Name").create());
        options.addOption(OptionBuilder.withLongOpt("chunk-read-ahead-pages").withDescription("The number of pages to read ahead when doing a disk read on the chunk store." + " \nDefaults to: \n 128/io-chunk-size or 1 if greater than 128").hasArg().withArgName("NUMBER").create());
        options.addOption(OptionBuilder.withLongOpt("chunk-store-gc-schedule").withDescription("The schedule, in cron format, to check for unclaimed chunks within the Dedup Storage Engine. " + "This should happen less frequently than the io-claim-chunks-schedule. \n Defaults to: \n 0 0 0/2 * * ?").hasArg().withArgName("CRON Schedule").create());
        options.addOption(OptionBuilder.withLongOpt("chunk-store-eviction").withDescription("The duration, in hours, that chunks will be removed from Dedup Storage Engine if unclaimed. " + "This should happen less frequently than the io-claim-chunks-schedule. \n Defaults to: \n 6").hasArg().withArgName("HOURS").create());
        options.addOption(OptionBuilder.withLongOpt("chunk-store-size").withDescription("The size in MB,TB,GB of the Dedup Storeage Engine. " + "This . \n Defaults to: \n The size of the Volume").hasArg().withArgName("MB|GB|TB").create());
        options.addOption(OptionBuilder.withLongOpt("hash-size").withDescription("This is the size in bytes of the unique hash. In version 1.0 and below this would default to 24 and for newer" + "versions this will default to 16. Set this to 24 if you would like to make the DSE backwards compatible to versions" + "below 1.0.1 ." + "This . \n Defaults to: \n 5MB").hasArg().withArgName("16 or 24 bytes").create());
        options.addOption(OptionBuilder.withLongOpt("chunk-store-read-cache").withDescription("The size in MB of the Dedup Storeage Engine's read cache. Its useful to set this if you have high number of reads" + " for AWS/Cloud storage " + "This . \n Defaults to: \n 5MB").hasArg().withArgName("Megabytes").create());
        options.addOption(OptionBuilder.withLongOpt("chunk-store-encrypt").withDescription("Whether or not to Encrypt chunks within the Dedup Storage Engine. The encryption key is generated automatically." + " For AWS this is a good option to enable. The default for this is" + " false").hasArg().withArgName("true|false").create());
        options.addOption(OptionBuilder.withLongOpt("chunk-store-dirty-timeout").withDescription("The timeout, in milliseconds, for a previous read for the same chunk to finish within the Dedup Storage Engine. " + "For AWS with slow links you may want to set this to a higher number. The default for this is" + " 1000 ms.").hasArg().withArgName("Milliseconds").create());
        options.addOption(OptionBuilder.withLongOpt("aws-enabled").withDescription("Set to true to enable this volume to store to Amazon S3 Cloud Storage. aws-secret-key, aws-access-key, and aws-bucket-name will also need to be set. ").hasArg().withArgName("true|false").create());
        options.addOption(OptionBuilder.withLongOpt("aws-secret-key").withDescription("Set to the value of Amazon S3 Cloud Storage secret key. aws-enabled, aws-access-key, and aws-bucket-name will also need to be set. ").hasArg().withArgName("S3 Secret Key").create());
        options.addOption(OptionBuilder.withLongOpt("aws-access-key").withDescription("Set to the value of Amazon S3 Cloud Storage access key. aws-enabled, aws-secret-key, and aws-bucket-name will also need to be set. ").hasArg().withArgName("S3 Access Key").create());
        options.addOption(OptionBuilder.withLongOpt("aws-bucket-name").withDescription("Set to the value of Amazon S3 Cloud Storage bucket name. This will need to be unique and a could be set the the access key if all else fails. aws-enabled, aws-secret-key, and aws-secret-key will also need to be set. ").hasArg().withArgName("Unique S3 Bucket Name").create());
        options.addOption(OptionBuilder.withLongOpt("aws-compress").withDescription("Compress AWS chunks before they are sent to the S3 Cloud Storeage bucket. By default this is set to true. Set it to  false for volumes that hold data that does not compress well, such as pictures and  movies").hasArg().withArgName("true|false").create());
        options.addOption(OptionBuilder.withLongOpt("gs-enabled").withDescription("Set to true to enable this volume to store to Google Cloud Storage. gs-secret-key, gs-access-key, and gs-bucket-name will also need to be set. ").hasArg().withArgName("true|false").create());
        options.addOption(OptionBuilder.withLongOpt("gs-secret-key").withDescription("Set to the value of Google Cloud Storage secret key. gs-enabled, gs-access-key, and gs-bucket-name will also need to be set. ").hasArg().withArgName("Google Secret Key").create());
        options.addOption(OptionBuilder.withLongOpt("aws-access-key").withDescription("Set to the value of the Google Cloud Storage access key. gs-enabled, gs-secret-key, and gs-bucket-name will also need to be set. ").hasArg().withArgName("Google Access Key").create());
        options.addOption(OptionBuilder.withLongOpt("gs-bucket-name").withDescription("Set to the value of the Google Cloud Storage bucket name. This will need to be unique and a could be set the the access key if all else fails. gs-enabled, gs-secret-key, and gs-secret-key will also need to be set. ").hasArg().withArgName("Unique Google Bucket Name").create());
        options.addOption(OptionBuilder.withLongOpt("gs-compress").withDescription("Compress chunks before they are sent to the Google Cloud Storeage bucket. By default this is set to true. Set it to  false for volumes that hold data that does not compress well, such as pictures and  movies").hasArg().withArgName("true|false").create());
        options.addOption(OptionBuilder.withLongOpt("dse-enable-udp").withDescription("Enable udp for some communication between Volume and DSE. Defaults to false").create());
        options.addOption(OptionBuilder.withLongOpt("dse-listen-ip").withDescription("Host name or IPv4 Address to listen on for incoming connections. Defaults to \"0.0.0.0\"").hasArg().withArgName("IPv4 Address").create());
        options.addOption(OptionBuilder.withLongOpt("dse-listen-port").withDescription("TCP and UDP Port to listen on for incoming connections. Defaults to 2222").hasArg().withArgName("IP Port").create());
        options.addOption(OptionBuilder.withLongOpt("dse-upstream-enabled").withDescription("Enable Upstream Dedup Storage Engine communication").create());
        options.addOption(OptionBuilder.withLongOpt("dse-upstream-host").withDescription("Host name or IPv4 Address ").hasArg().withArgName("FQDN or IPv4 Address").create());
        options.addOption(OptionBuilder.withLongOpt("dse-upstream-host-port").withDescription("TCP and UDP Port to listen on for incoming connections. Defaults to 2222").hasArg().withArgName("IP Port").create());
        options.addOption(OptionBuilder.withLongOpt("dse-upstream-password").withDescription("SDFSCLI Password of upstream host. Defaults to \"admin\"").hasArg().withArgName("STRING").create());
        options.addOption(OptionBuilder.withLongOpt("dse-listen-port").withDescription("TCP and UDP Port to listen on for incoming connections. Defaults to 2222").hasArg().withArgName("IP Port").create());
        options.addOption(OptionBuilder.withLongOpt("dse-enable-network").withDescription("Enable Network Services for Dedup Storage Enginge to serve outside hosts").create());
        options.addOption(OptionBuilder.withLongOpt("enable-replication-master").withDescription("Enable this volume as a replication master").create());
        options.addOption(OptionBuilder.withLongOpt("enable-replication-slave").withDescription("Enable this volume as a replication slave").create());
        options.addOption(OptionBuilder.withLongOpt("replication-master").withDescription("The Replication master for this slave").hasArg().withArgName("FQDN or IPv4 Address").create());
        options.addOption(OptionBuilder.withLongOpt("replication-master-password").withDescription("The Replication master sdfscli password. Defaults to \"admin\"").hasArg().withArgName("STRING").create());
        return options;
    }
